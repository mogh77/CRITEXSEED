{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tensorflow2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mogh77/CRITEXSEED/blob/master/tensorflow2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGFY2MoPLpe3",
        "colab_type": "code",
        "outputId": "a782efe0-d466-4b01-f6af-fa6f2fc65381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        }
      },
      "source": [
        "import h5py\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.framework import ops\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOCjE7HPSxi5",
        "colab_type": "code",
        "outputId": "b93881a7-c433-4d8a-bb83-f1ea38e6da15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgMfY4Py4tmr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_to_one_hot(Y, C):\n",
        "    Y = np.eye(C)[Y.reshape(-1)].T\n",
        "    return Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7sTP8g84E4N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_mini_batches(X, Y, mini_batch_size = 64, seed = 0):\n",
        "    \"\"\"\n",
        "    Creates a list of random minibatches from (X, Y)\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input data, of shape (input size, number of examples)\n",
        "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
        "    mini_batch_size - size of the mini-batches, integer\n",
        "    seed -- this is only for the purpose of grading, so that you're \"random minibatches are the same as ours.\n",
        "    \n",
        "    Returns:\n",
        "    mini_batches -- list of synchronous (mini_batch_X, mini_batch_Y)\n",
        "    \"\"\"\n",
        "    \n",
        "    m = X.shape[1]                  # number of training examples\n",
        "    mini_batches = []\n",
        "    np.random.seed(seed)\n",
        "    \n",
        "    # Step 1: Shuffle (X, Y)\n",
        "    permutation = list(np.random.permutation(m))\n",
        "    shuffled_X = X[:, permutation]\n",
        "    shuffled_Y = Y[:, permutation].reshape((Y.shape[0],m))\n",
        "\n",
        "    # Step 2: Partition (shuffled_X, shuffled_Y). Minus the end case.\n",
        "    num_complete_minibatches = math.floor(m/mini_batch_size) # number of mini batches of size mini_batch_size in your partitionning\n",
        "    for k in range(0, num_complete_minibatches):\n",
        "        mini_batch_X = shuffled_X[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch_Y = shuffled_Y[:, k * mini_batch_size : k * mini_batch_size + mini_batch_size]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    # Handling the end case (last mini-batch < mini_batch_size)\n",
        "    if m % mini_batch_size != 0:\n",
        "        mini_batch_X = shuffled_X[:, num_complete_minibatches * mini_batch_size : m]\n",
        "        mini_batch_Y = shuffled_Y[:, num_complete_minibatches * mini_batch_size : m]\n",
        "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
        "        mini_batches.append(mini_batch)\n",
        "    \n",
        "    return mini_batches"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65tCx0POMUgO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = h5py.File('/content/drive/My Drive/train_signs.h5', \"r\")\n",
        "X_train_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
        "Y_train_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
        "\n",
        "test_dataset = h5py.File('/content/drive/My Drive/test_signs.h5', \"r\")\n",
        "X_test_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
        "Y_test_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
        "\n",
        "classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoX83-MTUmxI",
        "colab_type": "code",
        "outputId": "fe90606f-e0be-40cf-f95a-84d22f957ddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        }
      },
      "source": [
        "# Example of a picture\n",
        "index = 0\n",
        "plt.imshow(X_train_orig[index])\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f88333f8ba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bV1xqq0aMKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljg12vG9f7z9",
        "colab_type": "code",
        "outputId": "c6c0c0ab-f698-4fd8-ef52-8c4db2bd2b9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "X_train_orig.shape\n",
        "Y_train_orig"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 2, ..., 2, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hABHQwPZCGr",
        "colab_type": "code",
        "outputId": "18baf9db-51ea-4987-891a-3249505d2fe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "# Flatten the training and test images\n",
        "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
        "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
        "# Normalize image vectors\n",
        "X_train = X_train_flatten/255.\n",
        "X_test = X_test_flatten/255.\n",
        "# Convert training and test labels to one hot matrices\n",
        "Y_train = convert_to_one_hot(Y_train_orig, 6)\n",
        "Y_test = convert_to_one_hot(Y_test_orig, 6)\n",
        "\n",
        "print (\"number of training examples = \" + str(X_train.shape[1]))\n",
        "print (\"number of test examples = \" + str(X_test.shape[1]))\n",
        "print (\"X_train shape: \" + str(X_train.shape))\n",
        "print (\"Y_train shape: \" + str(Y_train.shape))\n",
        "print (\"X_test shape: \" + str(X_test.shape))\n",
        "print (\"Y_test shape: \" + str(Y_test.shape))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of training examples = 1080\n",
            "number of test examples = 120\n",
            "X_train shape: (12288, 1080)\n",
            "Y_train shape: (6, 1080)\n",
            "X_test shape: (12288, 120)\n",
            "Y_test shape: (6, 120)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOjVCZmBhA4l",
        "colab_type": "code",
        "outputId": "a1a187f7-a5a1-4e78-ad35-3790752b489b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "Y_train"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 1., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkPD5HvAZe-3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_placeholders(n_x, n_y):\n",
        "    \"\"\"\n",
        "    Creates the placeholders for the tensorflow session.\n",
        "    \n",
        "    Arguments:\n",
        "    n_x -- scalar, size of an image vector (num_px * num_px = 64 * 64 * 3 = 12288)\n",
        "    n_y -- scalar, number of classes (from 0 to 5, so -> 6)\n",
        "    \n",
        "    Returns:\n",
        "    X -- placeholder for the data input, of shape [n_x, None] and dtype \"float\"\n",
        "    Y -- placeholder for the input labels, of shape [n_y, None] and dtype \"float\"\n",
        "    \n",
        "    Tips:\n",
        "    - You will use None because it let's us be flexible on the number of examples you will for the placeholders.\n",
        "      In fact, the number of examples during test/train is different.\n",
        "    \"\"\"\n",
        "\n",
        "    ### START CODE HERE ### (approx. 2 lines)\n",
        "    X = tf.placeholder(tf.float32, [n_x, None], name=\"X\")\n",
        "    Y = tf.placeholder(tf.float32, [n_y, None], name=\"Y\")\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return X, Y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7qB4GsRdn1X",
        "colab_type": "code",
        "outputId": "68d505b9-d362-4fae-a2c9-7ff806ec2b93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "X, Y = create_placeholders(12288, 6)\n",
        "print(\"X = \" + str(X))\n",
        "print(\"Y = \" + str(Y))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X = Tensor(\"X:0\", shape=(12288, ?), dtype=float32)\n",
            "Y = Tensor(\"Y:0\", shape=(6, ?), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGIAxShlduq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_parameters():\n",
        "    \"\"\"\n",
        "    Initializes parameters to build a neural network with tensorflow. The shapes are:\n",
        "                        W1 : [25, 12288]\n",
        "                        b1 : [25, 1]\n",
        "                        W2 : [12, 25]\n",
        "                        b2 : [12, 1]\n",
        "                        W3 : [6, 12]\n",
        "                        b3 : [6, 1]\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- a dictionary of tensors containing W1, b1, W2, b2, W3, b3\n",
        "    \"\"\"\n",
        "    \n",
        "    tf.set_random_seed(1)                   # so that your \"random\" numbers match ours\n",
        "        \n",
        "    ### START CODE HERE ### (approx. 6 lines of code)\n",
        "    W1 = tf.get_variable(\"W1\", [25, 12288], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
        "    b1 = tf.get_variable(\"b1\", [25, 1], initializer = tf.zeros_initializer())\n",
        "    W2 = tf.get_variable(\"W2\", [12, 25], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
        "    b2 = tf.get_variable(\"b2\", [12, 1], initializer = tf.zeros_initializer())\n",
        "    W3 = tf.get_variable(\"W3\", [6, 12], initializer = tf.contrib.layers.xavier_initializer(seed=1))\n",
        "    b3 = tf.get_variable(\"b3\", [6, 1], initializer = tf.zeros_initializer())\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    parameters = {\"W1\": W1,\n",
        "                  \"b1\": b1,\n",
        "                  \"W2\": W2,\n",
        "                  \"b2\": b2,\n",
        "                  \"W3\": W3,\n",
        "                  \"b3\": b3}\n",
        "    \n",
        "    return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gE24Cmyd7j3",
        "colab_type": "code",
        "outputId": "fa0a229a-cd17-42b5-8016-c62682764498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "\n",
        "\n",
        "tf.reset_default_graph()\n",
        "with tf.Session() as sess:\n",
        "    parameters = initialize_parameters()\n",
        "    print(\"W1 = \" + str(parameters[\"W1\"]))\n",
        "    print(\"b1 = \" + str(parameters[\"b1\"]))\n",
        "    print(\"W2 = \" + str(parameters[\"W2\"]))\n",
        "    print(\"b2 = \" + str(parameters[\"b2\"]))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "W1 = <tf.Variable 'W1:0' shape=(25, 12288) dtype=float32_ref>\n",
            "b1 = <tf.Variable 'b1:0' shape=(25, 1) dtype=float32_ref>\n",
            "W2 = <tf.Variable 'W2:0' shape=(12, 25) dtype=float32_ref>\n",
            "b2 = <tf.Variable 'b2:0' shape=(12, 1) dtype=float32_ref>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBKJUokehk2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_propagation(X, parameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
        "                  the shapes are given in initialize_parameters\n",
        "\n",
        "    Returns:\n",
        "    Z3 -- the output of the last LINEAR unit\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve the parameters from the dictionary \"parameters\" \n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3']\n",
        "    \n",
        "    ### START CODE HERE ### (approx. 5 lines)              # Numpy Equivalents:\n",
        "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
        "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
        "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
        "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
        "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return Z3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HBNnMROiUNp",
        "colab_type": "code",
        "outputId": "6da65c73-cca6-4ce8-b766-44126ac342eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    X, Y = create_placeholders(12288, 6)\n",
        "    parameters = initialize_parameters()\n",
        "    Z3 = forward_propagation(X, parameters)\n",
        "    print(\"Z3 = \" + str(Z3))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Z3 = Tensor(\"Add_2:0\", shape=(6, ?), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtJjsvFyiYHU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_cost(Z3, Y):\n",
        "    \"\"\"\n",
        "    Computes the cost\n",
        "    \n",
        "    Arguments:\n",
        "    Z3 -- output of forward propagation (output of the last LINEAR unit), of shape (6, number of examples)\n",
        "    Y -- \"true\" labels vector placeholder, same shape as Z3\n",
        "    \n",
        "    Returns:\n",
        "    cost - Tensor of the cost function\n",
        "    \"\"\"\n",
        "    \n",
        "    # to fit the tensorflow requirement for tf.nn.softmax_cross_entropy_with_logits(...,...)\n",
        "    logits = tf.transpose(Z3)\n",
        "    labels = tf.transpose(Y)\n",
        "    \n",
        "    ### START CODE HERE ### (1 line of code)\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels))\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    return cost"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPLx2fIqk_RI",
        "colab_type": "code",
        "outputId": "45bd5c20-335f-4ac9-fb2a-f9bf0abac9d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        }
      },
      "source": [
        "tf.reset_default_graph()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    X, Y = create_placeholders(12288, 6)\n",
        "    parameters = initialize_parameters()\n",
        "    Z3 = forward_propagation(X, parameters)\n",
        "    cost = compute_cost(Z3, Y)\n",
        "    print(\"cost = \" + str(cost))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-16-86fea8b55355>:18: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "\n",
            "Future major versions of TensorFlow will allow gradients to flow\n",
            "into the labels input on backprop by default.\n",
            "\n",
            "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
            "\n",
            "cost = Tensor(\"Mean:0\", shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F0iG_CUmGkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7Rjob4e0Ifn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model(X_train, Y_train, X_test, Y_test, learning_rate = 0.0001,\n",
        "          num_epochs = 1500, minibatch_size = 32, print_cost = True):\n",
        "    \"\"\"\n",
        "    Implements a three-layer tensorflow neural network: LINEAR->RELU->LINEAR->RELU->LINEAR->SOFTMAX.\n",
        "    \n",
        "    Arguments:\n",
        "    X_train -- training set, of shape (input size = 12288, number of training examples = 1080)\n",
        "    Y_train -- test set, of shape (output size = 6, number of training examples = 1080)\n",
        "    X_test -- training set, of shape (input size = 12288, number of training examples = 120)\n",
        "    Y_test -- test set, of shape (output size = 6, number of test examples = 120)\n",
        "    learning_rate -- learning rate of the optimization\n",
        "    num_epochs -- number of epochs of the optimization loop\n",
        "    minibatch_size -- size of a minibatch\n",
        "    print_cost -- True to print the cost every 100 epochs\n",
        "    \n",
        "    Returns:\n",
        "    parameters -- parameters learnt by the model. They can then be used to predict.\n",
        "    \"\"\"\n",
        "    \n",
        "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
        "    tf.set_random_seed(1)                             # to keep consistent results\n",
        "    seed = 3                                          # to keep consistent results\n",
        "    (n_x, m) = X_train.shape                          # (n_x: input size, m : number of examples in the train set)\n",
        "    n_y = Y_train.shape[0]                            # n_y : output size\n",
        "    costs = []                                        # To keep track of the cost\n",
        "    \n",
        "    # Create Placeholders of shape (n_x, n_y)\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    X, Y = create_placeholders(n_x, n_y)\n",
        "    ### END CODE HERE ###\n",
        "\n",
        "    # Initialize parameters\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    parameters = initialize_parameters()\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Forward propagation: Build the forward propagation in the tensorflow graph\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    Z3 = forward_propagation(X, parameters)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Cost function: Add cost function to tensorflow graph\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    cost = compute_cost(Z3, Y)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer.\n",
        "    ### START CODE HERE ### (1 line)\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
        "    ### END CODE HERE ###\n",
        "    \n",
        "    # Initialize all the variables\n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    # Start the session to compute the tensorflow graph\n",
        "    with tf.Session() as sess:\n",
        "        \n",
        "        # Run the initialization\n",
        "        sess.run(init)\n",
        "        \n",
        "        # Do the training loop\n",
        "        for epoch in range(num_epochs):\n",
        "\n",
        "            epoch_cost = 0.                       # Defines a cost related to an epoch\n",
        "            num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
        "            seed = seed + 1\n",
        "            minibatches = random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
        "\n",
        "            for minibatch in minibatches:\n",
        "\n",
        "                # Select a minibatch\n",
        "                (minibatch_X, minibatch_Y) = minibatch\n",
        "                \n",
        "                # IMPORTANT: The line that runs the graph on a minibatch.\n",
        "                # Run the session to execute the \"optimizer\" and the \"cost\", the feedict should contain a minibatch for (X,Y).\n",
        "                ### START CODE HERE ### (1 line)\n",
        "                _ , minibatch_cost = sess.run([optimizer, cost], feed_dict={X: minibatch_X, Y: minibatch_Y})\n",
        "                ### END CODE HERE ###\n",
        "                \n",
        "                epoch_cost += minibatch_cost / num_minibatches\n",
        "\n",
        "            # Print the cost every epoch\n",
        "            if print_cost == True and epoch % 100 == 0:\n",
        "                print (\"Cost after epoch %i: %f\" % (epoch, epoch_cost))\n",
        "            if print_cost == True and epoch % 5 == 0:\n",
        "                costs.append(epoch_cost)\n",
        "                \n",
        "        # plot the cost\n",
        "        plt.plot(np.squeeze(costs))\n",
        "        plt.ylabel('cost')\n",
        "        plt.xlabel('iterations (per tens)')\n",
        "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
        "        plt.show()\n",
        "\n",
        "        # lets save the parameters in a variable\n",
        "        parameters = sess.run(parameters)\n",
        "        print(\"Parameters have been trained!\")\n",
        "\n",
        "        # Calculate the correct predictions\n",
        "        correct_prediction = tf.equal(tf.argmax(Z3), tf.argmax(Y))\n",
        "\n",
        "        # Calculate accuracy on the test set\n",
        "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
        "\n",
        "        print(\"Train Accuracy:\", accuracy.eval({X: X_train, Y: Y_train}))\n",
        "        print(\"Test Accuracy:\", accuracy.eval({X: X_test, Y: Y_test}))\n",
        "        \n",
        "        return parameters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ldn6Gmzp0tUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sIyU5tk0wZz",
        "colab_type": "code",
        "outputId": "2cbcbd78-6b43-47c7-8e54-ccbc8ec52833",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        }
      },
      "source": [
        "\n",
        "\n",
        "parameters = model(X_train, Y_train, X_test, Y_test)\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cost after epoch 0: 1.855702\n",
            "Cost after epoch 100: 1.016458\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-55918c59b067>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-4886e9cee2bb>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(X_train, Y_train, X_test, Y_test, learning_rate, num_epochs, minibatch_size, print_cost)\u001b[0m\n\u001b[1;32m     78\u001b[0m                 \u001b[0;31m### END CODE HERE ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mepoch_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mminibatch_cost\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_minibatches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0;31m# Print the cost every epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEQfhlg703bH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def forward_propagation_for_predict(X, parameters):\n",
        "    \"\"\"\n",
        "    Implements the forward propagation for the model: LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SOFTMAX\n",
        "    \n",
        "    Arguments:\n",
        "    X -- input dataset placeholder, of shape (input size, number of examples)\n",
        "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", \"W2\", \"b2\", \"W3\", \"b3\"\n",
        "                  the shapes are given in initialize_parameters\n",
        "\n",
        "    Returns:\n",
        "    Z3 -- the output of the last LINEAR unit\n",
        "    \"\"\"\n",
        "    \n",
        "    # Retrieve the parameters from the dictionary \"parameters\" \n",
        "    W1 = parameters['W1']\n",
        "    b1 = parameters['b1']\n",
        "    W2 = parameters['W2']\n",
        "    b2 = parameters['b2']\n",
        "    W3 = parameters['W3']\n",
        "    b3 = parameters['b3'] \n",
        "                                                           # Numpy Equivalents:\n",
        "    Z1 = tf.add(tf.matmul(W1, X), b1)                      # Z1 = np.dot(W1, X) + b1\n",
        "    A1 = tf.nn.relu(Z1)                                    # A1 = relu(Z1)\n",
        "    Z2 = tf.add(tf.matmul(W2, A1), b2)                     # Z2 = np.dot(W2, a1) + b2\n",
        "    A2 = tf.nn.relu(Z2)                                    # A2 = relu(Z2)\n",
        "    Z3 = tf.add(tf.matmul(W3, A2), b3)                     # Z3 = np.dot(W3,Z2) + b3\n",
        "    \n",
        "    return Z3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7NPk23n2RYK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(X, parameters):\n",
        "    \n",
        "    W1 = tf.convert_to_tensor(parameters[\"W1\"])\n",
        "    b1 = tf.convert_to_tensor(parameters[\"b1\"])\n",
        "    W2 = tf.convert_to_tensor(parameters[\"W2\"])\n",
        "    b2 = tf.convert_to_tensor(parameters[\"b2\"])\n",
        "    W3 = tf.convert_to_tensor(parameters[\"W3\"])\n",
        "    b3 = tf.convert_to_tensor(parameters[\"b3\"])\n",
        "    \n",
        "    params = {\"W1\": W1,\n",
        "              \"b1\": b1,\n",
        "              \"W2\": W2,\n",
        "              \"b2\": b2,\n",
        "              \"W3\": W3,\n",
        "              \"b3\": b3}\n",
        "    \n",
        "    x = tf.placeholder(\"float\", [12288, 1])\n",
        "    \n",
        "    z3 = forward_propagation_for_predict(x, params)\n",
        "    p = tf.argmax(z3)\n",
        "    \n",
        "    sess = tf.Session()\n",
        "    prediction = sess.run(p, feed_dict = {x: X})\n",
        "        \n",
        "    return prediction"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiWWXqEd8g3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pillow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYnNt99K-D6E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install scipy==1.1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs_VGdyp2plQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy\n",
        "from PIL import Image\n",
        "from scipy import misc\n",
        "\n",
        "\n",
        "## START CODE HERE ## (PUT YOUR IMAGE NAME) \n",
        "my_image = \"untitled.tif\"\n",
        "## END CODE HERE ##\n",
        "\n",
        "# We preprocess your image to fit your algorithm.\n",
        "fname = \"/content/drive/My Drive/\" + my_image\n",
        "image = np.array(misc.imread(fname, flatten=False))\n",
        "my_image = scipy.misc.imresize(image, size=(64, 64)).reshape((1, 64 * 64 * 3)).T\n",
        "my_image_prediction = predict(my_image, parameters)\n",
        "\n",
        "plt.imshow(image)\n",
        "print(\"Your algorithm predicts: y = \" + str(np.squeeze(my_image_prediction)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwESVz_D8BWW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}